{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing packages and loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from time import time \n",
    "from tqdm import tqdm \n",
    "from glob import glob\n",
    "from os.path import dirname as up\n",
    "from rasterio.enums import Resampling\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from timm.utils import ModelEma\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from middle_fusion_rgb_hs_dem import Middle_fusion_en as mf_rgb_hs_dem\n",
    "from vscp import VSCP\n",
    "from test_time_aug import TTA\n",
    "from metrics import Evaluation, confusion_matrix\n",
    "from assets import bool_flag, cosine_scheduler, labels, mados_cat_mapping, mados_color_mapping\n",
    "#from dataset import MADOS, gen_weights, class_distr, bands_mean, bands_std\n",
    "from dataset_crop import MADOS, gen_weights, class_distr, bands_mean, bands_std\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = os.path.join(\"/home/ubuntu/Tesi/Middle-Fusion-Unet\", 'log')\n",
    "time_now = str(int(time() / 60))\n",
    "log_file = os.path.join(log_directory, 'log_marinext_' + time_now + '.log')\n",
    "\n",
    "logging.basicConfig(filename=log_file, filemode='a', level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.info('*' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    # Pytorch Reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    # DataLoader Workers Reproducibility\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbe440af470>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_all(0)\n",
    "g=torch.Generator()\n",
    "g.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 08:34:14.874246: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 08:34:20.208752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(os.path.join(log_directory, 'logs', 'tsboard_segm'+'_'+time_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_path = os.path.join(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\",'splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load train set to memory:   0%|          | 0/175 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "Load train set to memory: 100%|██████████| 175/175 [02:10<00:00,  1.35it/s]\n",
      "Load val set to memory: 100%|██████████| 175/175 [01:15<00:00,  2.31it/s]\n",
      "Load test set to memory: 100%|██████████| 175/175 [01:13<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_train = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'train')\n",
    "dataset_val = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'val')\n",
    "dataset_test = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train, \n",
    "                          batch_size = 5, \n",
    "                          shuffle = True,\n",
    "                          num_workers = 0,           # 0 is the main process\n",
    "                          pin_memory = False,        # Use pinned memory or not\n",
    "                          prefetch_factor = 2,      # Number of sample loaded in advance by each worker\n",
    "                          persistent_workers= False, # This allows to maintain the workers Dataset instances alive.\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g,\n",
    "                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(dataset_val, \n",
    "                          batch_size = 5, \n",
    "                          shuffle = False,\n",
    "                          num_workers = 0,           # 0 is the main process\n",
    "                          pin_memory = False,        # Use pinned memory or not\n",
    "                          prefetch_factor = 2,      # Number of sample loaded in advance by each worker\n",
    "                          persistent_workers= False, # This allows to maintain the workers Dataset instances alive.\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset_test, \n",
    "                          batch_size = 1, \n",
    "                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU presence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gpu or cpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Middle_fusion_en(\n",
       "  (conv_rgb): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv_hs): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv_dem): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_en = mf_rgb_hs_dem(conf_rgb={'channels':[4,16,32], 'kernels':[3,3]},\n",
    "                          conf_hs={'channels':[6,16,32], 'kernels':[3,3]},\n",
    "                          conf_dem={'channels':[1,16,32], 'kernels':[3,3]})\n",
    "\n",
    "in_channels_middle_fusion = 32+32+32\n",
    "fusion_en.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(96, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.Unet('resnet18', in_channels=in_channels_middle_fusion, classes=15)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMA è una forma di media mobile che attribuisce pesi decrescenti ai dati nel tempo, con un peso maggiore ai dati più recenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ema = None\n",
    "if True:\n",
    "    model_ema = ModelEma(\n",
    "        model,\n",
    "        decay=0.999,\n",
    "        device=device,\n",
    "        resume='')\n",
    "    \n",
    "    ema_decay_schedule = cosine_scheduler(0.999, 0.999, 80, len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Cross Entropy Loss & adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor(np.array([64.39, 28.33, 70.90, 75.34, 75.33, 19.25, 5.67, 26.99, 53.84, 23.63, 15.65, 75.48, 75.03, 76.19, 20.38])).float()\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction= 'none', weight=weight.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_on_plateau=0\n",
    "if reduce_lr_on_plateau==1:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "else:\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, '[45,65]', gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "eval_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "model.train()\n",
    "li10=[]\n",
    "li20=[]\n",
    "li60=[]\n",
    "imli=[]\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    training_loss = []\n",
    "    training_batches = 0\n",
    "    n=1\n",
    "    \n",
    "    i_board = 0\n",
    "    for it, (image10, image20, image60, target) in enumerate(tqdm(train_loader, desc=\"training\")):\n",
    "\n",
    "        it = len(train_loader) * (epoch-1) + it  # global training iteration\n",
    "\n",
    "        #VSCP\n",
    "        image_augmented10, image_augmented20, image_augmented60, target_augmented = VSCP(\n",
    "            image10.cpu().detach().numpy(), \n",
    "            image20.cpu().detach().numpy(), \n",
    "            image60.cpu().detach().numpy(), \n",
    "            target.cpu().detach().numpy())\n",
    "        image10 = torch.cat([image10, torch.tensor(image_augmented10).to(image10.device)])\n",
    "        image20 = torch.cat([image20, torch.tensor(image_augmented20).to(image20.device)])\n",
    "        image60 = torch.cat([image60, torch.tensor(image_augmented60).to(image60.device)])\n",
    "        target = torch.cat([target, torch.tensor(target_augmented).to(target.device)])\n",
    "\n",
    "        image10 = image10.to(device)\n",
    "        image20 = image20.to(device)\n",
    "        image60 = image60.to(device)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        torch.use_deterministic_algorithms(False)\n",
    "        inp = image10, image20, image60\n",
    "        logit, li10, li20, li60, imli = fusion_en(inp, n, li10, li20, li60, image10, imli, epoch)\n",
    "        logits = F.upsample(input=model(logit), size=image10.size()[2:4], mode='bilinear')\n",
    "        n+=1\n",
    "        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "        logits = logits.reshape((-1,15))\n",
    "        target = target.reshape(-1)\n",
    "        mask = target != -1\n",
    "        logits = logits[mask]\n",
    "        target = target[mask]\n",
    "        loss = criterion(logits, target)\n",
    "        #loss = loss.mean()\n",
    "        loss = loss.sum() / weight[target].sum()\n",
    "        loss.backward()\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "        training_batches += target.shape[0]\n",
    "\n",
    "        training_loss.append((loss.data*target.shape[0]).tolist())\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), float('inf'))\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        model_ema.decay = ema_decay_schedule[it]\n",
    "        model_ema.update(model)\n",
    "        \n",
    "        # Write running loss\n",
    "        writer.add_scalar('training loss', loss , (epoch - 1) * len(train_loader)+i_board)\n",
    "        i_board+=1\n",
    "\n",
    "    logging.info(\"Training loss was: \" + str(sum(training_loss) / training_batches))\n",
    "    \n",
    "    logging.info(\"Saving models\")\n",
    "    model_dir = os.path.join(up(os.path.abspath(\"/home/ubuntu/Tesi/Middle-Fusion-Unet\")), 'trained_models_MF_Unet')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "    \n",
    "    # Start Evaluation\n",
    "    if epoch % eval_every == 0 or epoch==1:\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = []\n",
    "        val_batches = 0\n",
    "        y_true_val = []\n",
    "        y_predicted_val = []\n",
    "        \n",
    "        seed_all(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (image10, image20, image60, target) in tqdm(val_loader, desc=\"validating\"):\n",
    "\n",
    "                image10 = image10.to(device)\n",
    "                image20 = image20.to(device)\n",
    "                image60 = image60.to(device)\n",
    "                target = target.long().to(device)\n",
    "                \n",
    "                inp = image10, image20, image60\n",
    "                logit, li10, li20, li60, imli = fusion_en(inp, n, li10, li20, li60, image10, imli, epoch)\n",
    "                logits = F.upsample(input=model(logit), size=(target.shape[-2], target.shape[-1]), mode='bilinear')\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,15))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                loss = criterion(logits, target)\n",
    "                #loss = loss.mean()\n",
    "                loss = loss.sum() / weight[target].sum()\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                val_batches += target.shape[0]\n",
    "                val_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted_val += probs.argmax(1).tolist()\n",
    "                y_true_val += target.tolist()\n",
    "                    \n",
    "                \n",
    "            y_predicted_val = np.asarray(y_predicted_val)\n",
    "            y_true_val = np.asarray(y_true_val)\n",
    "            #acc_val = Evaluation(y_predicted_val, y_true_val)\n",
    "        # Save Scores    \n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"Evaluating model..\")\n",
    "        logging.info(\"Val loss was: \" + str(sum(val_loss) / val_batches))\n",
    "        logging.info(\"RESULTS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "        #logging.info(\"Evaluation: \" + str(acc_val))\n",
    "    \n",
    "        writer.add_scalars('Loss per epoch', {'Val loss':sum(val_loss) / val_batches, \n",
    "                                                'Train loss':sum(training_loss) / training_batches}, epoch)\n",
    "        \n",
    "        #writer.add_scalar('Precision/val macroPrec', acc_val[\"macroPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val microPrec', acc_val[\"microPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val weightPrec', acc_val[\"weightPrec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val macroRec', acc_val[\"macroRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val microRec', acc_val[\"microRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val weightRec', acc_val[\"weightRec\"] , epoch)\n",
    "        #writer.add_scalar('F1/val macroF1', acc_val[\"macroF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val microF1', acc_val[\"microF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val weightF1', acc_val[\"weightF1\"] , epoch)\n",
    "        #writer.add_scalar('IoU/val MacroIoU', acc_val[\"IoU\"] , epoch)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    # Start EMA Evaluation\n",
    "    if (epoch % eval_every == 0 or epoch==1):\n",
    "        \n",
    "        logging.info(\"Saving models\")\n",
    "        model_dir = os.path.join(up(os.path.abspath(\"/home/ubuntu/Tesi/Middle-Fusion-Unet\")), 'trained_models_MF_Unet')\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        torch.save(model_ema.ema.state_dict(), os.path.join(model_dir, 'model_ema.pth'))\n",
    "\n",
    "        val_loss_ema = []\n",
    "        val_batches_ema = 0\n",
    "        y_true_val_ema = []\n",
    "        y_predicted_val_ema = []\n",
    "                        \n",
    "        seed_all(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (image10, image20, image60, target) in tqdm(val_loader, desc=\"validating\"):\n",
    "                \n",
    "                image10 = image10.to(device)\n",
    "                image20 = image20.to(device)\n",
    "                image60 = image60.to(device)\n",
    "                target = target.long().to(device)\n",
    "                \n",
    "                inp = image10, image20, image60\n",
    "                logit, li10, li20, li60, imli = fusion_en(inp, n, li10, li20, li60, image10, imli, epoch)\n",
    "                logits = F.upsample(input=model_ema.ema(logit), size=(target.shape[-2], target.shape[-1]), mode='bilinear')\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,15))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                loss = criterion(logits, target)\n",
    "                #loss = loss.mean()\n",
    "                loss = loss.sum() / weight[target].sum()\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                val_batches_ema += target.shape[0]\n",
    "                val_loss_ema.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted_val_ema += probs.argmax(1).tolist()\n",
    "                y_true_val_ema += target.tolist()\n",
    "                \n",
    "            y_predicted_val_ema = np.asarray(y_predicted_val_ema)\n",
    "            y_true_val_ema = np.asarray(y_true_val_ema)\n",
    "            #acc_val_ema = Evaluation(y_predicted_val_ema, y_true_val_ema)\n",
    "        # Save Scores\n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"Evaluating EMA model..\")\n",
    "        logging.info(\"val loss was: \" + str(sum(val_loss_ema) / val_batches_ema))\n",
    "        logging.info(\"RESULTS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "        #logging.info(\"Evaluation: \" + str(acc_val_ema))\n",
    "        \n",
    "        writer.add_scalars('Loss per epoch (EMA)', {'val loss':sum(val_loss_ema) / val_batches_ema}, epoch)\n",
    "        #writer.add_scalar('Precision/val macroPrec (EMA)', acc_val_ema[\"macroPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val microPrec (EMA)', acc_val_ema[\"microPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val weightPrec (EMA)', acc_val_ema[\"weightPrec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val macroRec (EMA)', acc_val_ema[\"macroRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val microRec (EMA)', acc_val_ema[\"microRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val weightRec (EMA)', acc_val_ema[\"weightRec\"] , epoch)\n",
    "        #writer.add_scalar('F1/val macroF1 (EMA)', acc_val_ema[\"macroF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val microF1 (EMA)', acc_val_ema[\"microF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val weightF1 (EMA)', acc_val_ema[\"weightF1\"] , epoch)\n",
    "        #writer.add_scalar('IoU/val MacroIoU (EMA)', acc_val_ema[\"IoU\"] , epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list2 = []\n",
    "#models_files = glob(os.path.join(os.path.join(\"C:\\\\Users\\\\lucap\\\\OneDrive\\\\Desktop\\\\Tesi\\\\Python Code\\\\trained_models_finito\", '1'),'*.pth'))\n",
    "models_files = glob(os.path.join(os.path.join(\"/home/ubuntu/Tesi/trained_models_MF_Unet\"),'model_ema.pth'))\n",
    "#models_files = glob(\"C:\\Users\\lucap\\OneDrive\\Desktop\\Tesi\\trained_models\\10\\model_ema.pth\")\n",
    "\n",
    "for model_file in models_files:\n",
    "\n",
    "    model2 = smp.Unet('resnet18', in_channels=in_channels_middle_fusion, classes=15)\n",
    "    model2.to(device)\n",
    "\n",
    "    \n",
    "    logging.info('Loading model files from folder: %s' % model_file)\n",
    "\n",
    "    checkpoint = torch.load(model_file, map_location = device)\n",
    "    checkpoint = {k.replace('decode_head','decoder'):v for k,v in checkpoint.items() if ('proj1' not in k) and ('proj2' not in k)}\n",
    "\n",
    "    model2.load_state_dict(checkpoint)\n",
    "\n",
    "    del checkpoint  # dereference\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model2.eval()\n",
    "    \n",
    "    models_list2.append(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_predicted = []\n",
    "li10new = []\n",
    "li20new = []\n",
    "li60new = [] \n",
    "imlinew = []\n",
    "n = 1\n",
    "epoch=80                       \n",
    "with torch.no_grad():\n",
    "    for i, (image10, image20, image60, target) in enumerate(tqdm(test_loader, desc=\"testing\")):\n",
    "\n",
    "        image10 = TTA(image10)   \n",
    "        image20 = TTA(image20)   \n",
    "        image60 = TTA(image60)            \n",
    "\n",
    "        image10 = image10.to(device)\n",
    "        image20 = image20.to(device)\n",
    "        image60 = image60.to(device)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        seed_all(0)\n",
    "        \n",
    "        inp = image10, image20, image60\n",
    "        logit, li10new, li20new, li60new, imlinew = fusion_en(inp, n, li10new, li20new, li60new, image10, imlinew, epoch)\n",
    "        logits = F.upsample(input=model2(logit), size=(target.shape[-2], target.shape[-1]), mode='bilinear')\n",
    "        n+=1\n",
    "\n",
    "        # Accuracy metrics only on annotated pixels\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        predictions = probs.argmax(1)\n",
    "        \n",
    "        predictions = TTA(predictions, reverse_aggregation = True)\n",
    "            \n",
    "        predictions = predictions.reshape(-1)\n",
    "        target = target[0].reshape(-1)\n",
    "        mask = target != -1\n",
    "        \n",
    "        predictions = predictions[mask].cpu().numpy()\n",
    "        target = target[mask]\n",
    "        \n",
    "        target = target.cpu().numpy()\n",
    "\n",
    "        y_predicted += predictions.tolist()\n",
    "        y_true += target.tolist()\n",
    "\n",
    "    # Save Scores\n",
    "    #acc = Evaluation(y_predicted, y_true)\n",
    "    #logging.info(\"\\n\")\n",
    "    #logging.info(\"STATISTICS: \\n\")\n",
    "    #logging.info(\"Evaluation: \" + str(acc))\n",
    "    #print(\"Evaluation: \" + str(acc))\n",
    "    conf_mat = confusion_matrix(y_true, y_predicted, labels, True)\n",
    "    logging.info(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "    print(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
