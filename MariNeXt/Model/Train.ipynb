{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing packages and loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from time import time \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from os.path import dirname as up\n",
    "from rasterio.enums import Resampling\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from timm.utils import ModelEma\n",
    "\n",
    "from marinext_wrapper import MariNext\n",
    "\n",
    "from vscp import VSCP\n",
    "from test_time_aug import TTA\n",
    "from metrics import Evaluation, confusion_matrix\n",
    "from assets import bool_flag, cosine_scheduler, labels, mados_cat_mapping, mados_color_mapping\n",
    "from dataset import MADOS, gen_weights, class_distr, bands_mean, bands_std\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#from dataset_crop import MADOS, gen_weights, class_distr, bands_mean, bands_std\n",
    "#torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = os.path.join(\"/home/ubuntu/Tesi/Early-Fusion\", 'log')\n",
    "time_now = str(int(time() / 60))\n",
    "log_file = os.path.join(log_directory, 'log_marinext_' + time_now + '.log')\n",
    "\n",
    "logging.basicConfig(filename=log_file, filemode='a', level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.info('*' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    # Pytorch Reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    # DataLoader Workers Reproducibility\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 14:01:34.414368: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 14:01:39.193337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "seed_all(0)\n",
    "g=torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "writer = SummaryWriter(os.path.join(log_directory, 'logs', 'tsboard_segm'+'_'+time_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load train set to memory:   0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "Load train set to memory: 100%|██████████| 175/175 [03:00<00:00,  1.03s/it]\n",
      "Load val set to memory: 100%|██████████| 175/175 [01:14<00:00,  2.34it/s]\n",
      "Load test set to memory: 100%|██████████| 175/175 [01:14<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "splits_path = os.path.join(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\",'splits')\n",
    "\n",
    "dataset_train = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'train')\n",
    "dataset_val = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'val')\n",
    "dataset_test = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train, \n",
    "                          batch_size = 5, \n",
    "                          shuffle = True,\n",
    "                          num_workers = 0,           # 0 is the main process\n",
    "                          pin_memory = False,        # Use pinned memory or not\n",
    "                          prefetch_factor = 2,      # Number of sample loaded in advance by each worker\n",
    "                          persistent_workers= False, # This allows to maintain the workers Dataset instances alive.\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g,\n",
    "                          drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(dataset_val, \n",
    "                        batch_size = 5, \n",
    "                        shuffle = False,\n",
    "                        num_workers = 0,\n",
    "                        pin_memory = False,\n",
    "                        prefetch_factor = 2,\n",
    "                        persistent_workers= False,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g)\n",
    "\n",
    "test_loader = DataLoader(dataset_test, \n",
    "                         batch_size = 1, \n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU presence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Tesi/Early-Fusion/Model/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial True\n",
      "S 1\n",
      "D 512\n",
      "R 16\n",
      "train_steps 6\n",
      "eval_steps 7\n",
      "inv_t 100\n",
      "eta 0.9\n",
      "rand_init True\n",
      "init cfg None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MariNext(\n",
       "  (backbone): MSCAN(\n",
       "    (patch_embed1): StemConv(\n",
       "      (proj): Sequential(\n",
       "        (0): Conv2d(11, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): _BatchNormXd(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (4): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "            (conv0_1): Conv2d(32, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=32)\n",
       "            (conv0_2): Conv2d(32, 32, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=32)\n",
       "            (conv1_1): Conv2d(32, 32, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=32)\n",
       "            (conv1_2): Conv2d(32, 32, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=32)\n",
       "            (conv2_1): Conv2d(32, 32, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=32)\n",
       "            (conv2_2): Conv2d(32, 32, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=32)\n",
       "            (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "            (conv0_1): Conv2d(32, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=32)\n",
       "            (conv0_2): Conv2d(32, 32, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=32)\n",
       "            (conv1_1): Conv2d(32, 32, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=32)\n",
       "            (conv1_2): Conv2d(32, 32, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=32)\n",
       "            (conv2_1): Conv2d(32, 32, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=32)\n",
       "            (conv2_2): Conv2d(32, 32, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=32)\n",
       "            (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "            (conv0_1): Conv2d(32, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=32)\n",
       "            (conv0_2): Conv2d(32, 32, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=32)\n",
       "            (conv1_1): Conv2d(32, 32, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=32)\n",
       "            (conv1_2): Conv2d(32, 32, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=32)\n",
       "            (conv2_1): Conv2d(32, 32, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=32)\n",
       "            (conv2_2): Conv2d(32, 32, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=32)\n",
       "            (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block2): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
       "            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)\n",
       "            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)\n",
       "            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)\n",
       "            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)\n",
       "            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)\n",
       "            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)\n",
       "            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
       "            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)\n",
       "            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)\n",
       "            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)\n",
       "            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)\n",
       "            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)\n",
       "            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)\n",
       "            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
       "            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)\n",
       "            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)\n",
       "            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)\n",
       "            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)\n",
       "            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)\n",
       "            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)\n",
       "            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block3): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160)\n",
       "            (conv0_1): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=160)\n",
       "            (conv0_2): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=160)\n",
       "            (conv1_1): Conv2d(160, 160, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=160)\n",
       "            (conv1_2): Conv2d(160, 160, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=160)\n",
       "            (conv2_1): Conv2d(160, 160, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=160)\n",
       "            (conv2_2): Conv2d(160, 160, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=160)\n",
       "            (conv3): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160)\n",
       "            (conv0_1): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=160)\n",
       "            (conv0_2): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=160)\n",
       "            (conv1_1): Conv2d(160, 160, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=160)\n",
       "            (conv1_2): Conv2d(160, 160, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=160)\n",
       "            (conv2_1): Conv2d(160, 160, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=160)\n",
       "            (conv2_2): Conv2d(160, 160, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=160)\n",
       "            (conv3): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160)\n",
       "            (conv0_1): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=160)\n",
       "            (conv0_2): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=160)\n",
       "            (conv1_1): Conv2d(160, 160, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=160)\n",
       "            (conv1_2): Conv2d(160, 160, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=160)\n",
       "            (conv2_1): Conv2d(160, 160, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=160)\n",
       "            (conv2_2): Conv2d(160, 160, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=160)\n",
       "            (conv3): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160)\n",
       "            (conv0_1): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=160)\n",
       "            (conv0_2): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=160)\n",
       "            (conv1_1): Conv2d(160, 160, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=160)\n",
       "            (conv1_2): Conv2d(160, 160, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=160)\n",
       "            (conv2_1): Conv2d(160, 160, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=160)\n",
       "            (conv2_2): Conv2d(160, 160, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=160)\n",
       "            (conv3): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160)\n",
       "            (conv0_1): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=160)\n",
       "            (conv0_2): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=160)\n",
       "            (conv1_1): Conv2d(160, 160, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=160)\n",
       "            (conv1_2): Conv2d(160, 160, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=160)\n",
       "            (conv2_1): Conv2d(160, 160, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=160)\n",
       "            (conv2_2): Conv2d(160, 160, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=160)\n",
       "            (conv3): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block4): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n",
       "            (conv0_1): Conv2d(256, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=256)\n",
       "            (conv0_2): Conv2d(256, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=256)\n",
       "            (conv1_1): Conv2d(256, 256, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=256)\n",
       "            (conv1_2): Conv2d(256, 256, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=256)\n",
       "            (conv2_1): Conv2d(256, 256, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=256)\n",
       "            (conv2_2): Conv2d(256, 256, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=256)\n",
       "            (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (attn): SpatialAttention(\n",
       "          (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU()\n",
       "          (spatial_gating_unit): AttentionModule(\n",
       "            (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n",
       "            (conv0_1): Conv2d(256, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=256)\n",
       "            (conv0_2): Conv2d(256, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=256)\n",
       "            (conv1_1): Conv2d(256, 256, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=256)\n",
       "            (conv1_2): Conv2d(256, 256, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=256)\n",
       "            (conv2_1): Conv2d(256, 256, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=256)\n",
       "            (conv2_2): Conv2d(256, 256, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=256)\n",
       "            (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decode_head): LightHamHead(\n",
       "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (conv_seg): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (squeeze): ConvModule(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (hamburger): Hamburger(\n",
       "      (ham_in): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (ham): NMF2D()\n",
       "      (ham_out): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (align): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use gpu or cpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "model = MariNext(11, 15)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "MariNext                                           [5, 15, 60, 60]           --\n",
       "├─MSCAN: 1-1                                       [5, 32, 60, 60]           --\n",
       "│    └─StemConv: 2-1                               [5, 3600, 32]             --\n",
       "│    │    └─Sequential: 3-1                        [5, 32, 60, 60]           6,336\n",
       "│    └─ModuleList: 2-2                             --                        --\n",
       "│    │    └─Block: 3-2                             [5, 3600, 32]             26,112\n",
       "│    │    └─Block: 3-3                             [5, 3600, 32]             26,112\n",
       "│    │    └─Block: 3-4                             [5, 3600, 32]             26,112\n",
       "│    └─LayerNorm: 2-3                              [5, 3600, 32]             64\n",
       "│    └─OverlapPatchEmbed: 2-4                      [5, 900, 64]              --\n",
       "│    │    └─Conv2d: 3-5                            [5, 64, 30, 30]           18,496\n",
       "│    │    └─_BatchNormXd: 3-6                      [5, 64, 30, 30]           128\n",
       "│    └─ModuleList: 2-5                             --                        --\n",
       "│    │    └─Block: 3-7                             [5, 900, 64]              91,136\n",
       "│    │    └─Block: 3-8                             [5, 900, 64]              91,136\n",
       "│    │    └─Block: 3-9                             [5, 900, 64]              91,136\n",
       "│    └─LayerNorm: 2-6                              [5, 900, 64]              128\n",
       "│    └─OverlapPatchEmbed: 2-7                      [5, 225, 160]             --\n",
       "│    │    └─Conv2d: 3-10                           [5, 160, 15, 15]          92,320\n",
       "│    │    └─_BatchNormXd: 3-11                     [5, 160, 15, 15]          320\n",
       "│    └─ModuleList: 2-8                             --                        --\n",
       "│    │    └─Block: 3-12                            [5, 225, 160]             307,840\n",
       "│    │    └─Block: 3-13                            [5, 225, 160]             307,840\n",
       "│    │    └─Block: 3-14                            [5, 225, 160]             307,840\n",
       "│    │    └─Block: 3-15                            [5, 225, 160]             307,840\n",
       "│    │    └─Block: 3-16                            [5, 225, 160]             307,840\n",
       "│    └─LayerNorm: 2-9                              [5, 225, 160]             320\n",
       "│    └─OverlapPatchEmbed: 2-10                     [5, 64, 256]              --\n",
       "│    │    └─Conv2d: 3-17                           [5, 256, 8, 8]            368,896\n",
       "│    │    └─_BatchNormXd: 3-18                     [5, 256, 8, 8]            512\n",
       "│    └─ModuleList: 2-11                            --                        --\n",
       "│    │    └─Block: 3-19                            [5, 64, 256]              762,880\n",
       "│    │    └─Block: 3-20                            [5, 64, 256]              762,880\n",
       "│    └─LayerNorm: 2-12                             [5, 64, 256]              512\n",
       "├─LightHamHead: 1-2                                [5, 15, 60, 60]           --\n",
       "│    └─ConvModule: 2-13                            [5, 256, 60, 60]          --\n",
       "│    │    └─Conv2d: 3-21                           [5, 256, 60, 60]          131,072\n",
       "│    │    └─GroupNorm: 3-22                        [5, 256, 60, 60]          512\n",
       "│    │    └─ReLU: 3-23                             [5, 256, 60, 60]          --\n",
       "│    └─Hamburger: 2-14                             [5, 256, 60, 60]          --\n",
       "│    │    └─ConvModule: 3-24                       [5, 256, 60, 60]          65,792\n",
       "│    │    └─NMF2D: 3-25                            [5, 256, 60, 60]          --\n",
       "│    │    └─ConvModule: 3-26                       [5, 256, 60, 60]          66,048\n",
       "│    └─ConvModule: 2-15                            [5, 256, 60, 60]          --\n",
       "│    │    └─Conv2d: 3-27                           [5, 256, 60, 60]          65,536\n",
       "│    │    └─GroupNorm: 3-28                        [5, 256, 60, 60]          512\n",
       "│    │    └─ReLU: 3-29                             [5, 256, 60, 60]          --\n",
       "│    └─Dropout2d: 2-16                             [5, 256, 60, 60]          --\n",
       "│    └─Conv2d: 2-17                                [5, 15, 60, 60]           3,855\n",
       "====================================================================================================\n",
       "Total params: 4,238,063\n",
       "Trainable params: 4,238,063\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 11.31\n",
       "====================================================================================================\n",
       "Input size (MB): 12.67\n",
       "Forward/backward pass size (MB): 1085.73\n",
       "Params size (MB): 16.94\n",
       "Estimated Total Size (MB): 1115.34\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "#summary(model, (11, 240, 240))\n",
    "summary(model, input_size=(5, 11, 240, 240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMA è una forma di media mobile che attribuisce pesi decrescenti ai dati nel tempo, con un peso maggiore ai dati più recenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ema = None\n",
    "if True:\n",
    "    model_ema = ModelEma(\n",
    "        model,\n",
    "        decay=0.999,\n",
    "        device=device,\n",
    "        resume='')\n",
    "    \n",
    "    ema_decay_schedule = cosine_scheduler(0.999, 0.999, 80, len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Cross Entropy Loss & adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor(np.array([64.39, 28.33, 70.90, 75.34, 75.33, 19.25, 5.67, 26.99, 53.84, 23.63, 15.65, 75.48, 75.03, 76.19, 20.38])).float()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction= 'mean', weight=weight.to(device), label_smoothing=0.0)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_on_plateau=0\n",
    "if reduce_lr_on_plateau==1:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "else:\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, '[45,65]', gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "eval_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/286 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "training: 100%|██████████| 286/286 [02:32<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.71it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.92it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.96it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.64it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.87it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.62it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.65it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.78it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.83it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.63it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.84it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.70it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.67it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.68it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.66it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.61it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.77it/s]\n",
      "training: 100%|██████████| 286/286 [02:32<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.68it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.85it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.87it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.92it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.70it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.92it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.77it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.65it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.70it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.76it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.66it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.80it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.63it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.65it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.71it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.84it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.65it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.83it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.71it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.71it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.92it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.62it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.71it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.90it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.80it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.64it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.87it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "training: 100%|██████████| 286/286 [02:32<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.64it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.84it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.71it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.87it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.70it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.63it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.62it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.88it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.64it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.68it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.68it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.78it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.70it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.68it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.76it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.93it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.66it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.76it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.86it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.73it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.64it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.94it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.62it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.88it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.67it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.71it/s]\n",
      "validating: 100%|██████████| 129/129 [00:15<00:00,  8.59it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.65it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.77it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.89it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.72it/s]\n",
      "training: 100%|██████████| 286/286 [02:29<00:00,  1.91it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.66it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.75it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.91it/s]\n",
      "training: 100%|██████████| 286/286 [02:31<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.74it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.88it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.89it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.70it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n",
      "training: 100%|██████████| 286/286 [02:30<00:00,  1.90it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.70it/s]\n",
      "validating: 100%|██████████| 129/129 [00:14<00:00,  8.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    training_loss = []\n",
    "    training_batches = 0\n",
    "\n",
    "    i_board = 0\n",
    "    for it, (image, target) in enumerate(tqdm(train_loader, desc=\"training\")):\n",
    "        \n",
    "        it = len(train_loader) * (epoch-1) + it  # global training iteration\n",
    "\n",
    "        #VSCP\n",
    "        image_augmented, target_augmented = VSCP(image.cpu().numpy(), target.cpu().numpy())\n",
    "        image = torch.cat([image, torch.tensor(image_augmented).to(image.device)])\n",
    "        target = torch.cat([target, torch.tensor(target_augmented).to(target.device)])\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = F.upsample(input=model(image), size=image.size()[2:4], mode='bilinear')\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward() \n",
    "\n",
    "        training_batches += target.shape[0]\n",
    "\n",
    "        training_loss.append((loss.data*target.shape[0]).tolist())\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), float('inf'))\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        model_ema.decay = ema_decay_schedule[it]\n",
    "        model_ema.update(model)\n",
    "        \n",
    "        # Write running loss\n",
    "        writer.add_scalar('training loss', loss , (epoch - 1) * len(train_loader)+i_board)\n",
    "        i_board+=1\n",
    "    \n",
    "    logging.info(\"Training loss was: \" + str(sum(training_loss) / training_batches))\n",
    "    \n",
    "    logging.info(\"Saving models\")\n",
    "    model_dir = os.path.join(up(os.path.abspath(\"/home/ubuntu/Tesi/Early-Fusion\")), 'trained_models_EF')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "    \n",
    "    # Start Evaluation\n",
    "    if epoch % eval_every == 0 or epoch==1:\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = []\n",
    "        val_batches = 0\n",
    "        y_true_val = []\n",
    "        y_predicted_val = []\n",
    "        \n",
    "        seed_all(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (image, target) in tqdm(val_loader, desc=\"validating\"):\n",
    "\n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                logits = model(image)\n",
    "                logits = F.upsample(input=logits, size=(target.shape[-2], target.shape[-1]), mode='bilinear')\n",
    "                loss = criterion(logits, target)\n",
    "                            \n",
    "                # Accuracy metrics only on annotated pixels\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,15))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                val_batches += target.shape[0]\n",
    "                val_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted_val += probs.argmax(1).tolist()\n",
    "                y_true_val += target.tolist()\n",
    "                    \n",
    "                \n",
    "            y_predicted_val = np.asarray(y_predicted_val)\n",
    "            y_true_val = np.asarray(y_true_val)\n",
    "            #acc_val = Evaluation(y_predicted_val, y_true_val)\n",
    "            #acc_val = accuracy_score(y_true_val, y_predicted_val)\n",
    "        # Save Scores    \n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"Evaluating model..\")\n",
    "        logging.info(\"Val loss was: \" + str(sum(val_loss) / val_batches))\n",
    "        logging.info(\"RESULTS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "        #logging.info(\"Evaluation: \" + str(acc_val))\n",
    "\n",
    "        writer.add_scalars('Loss per epoch', {'Val loss':sum(val_loss) / val_batches, \n",
    "                                                'Train loss':sum(training_loss) / training_batches}, epoch)\n",
    "        \n",
    "        #writer.add_scalar('Precision/val macroPrec', acc_val[\"macroPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val microPrec', acc_val[\"microPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val weightPrec', acc_val[\"weightPrec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val macroRec', acc_val[\"macroRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val microRec', acc_val[\"microRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val weightRec', acc_val[\"weightRec\"] , epoch)\n",
    "        #writer.add_scalar('F1/val macroF1', acc_val[\"macroF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val microF1', acc_val[\"microF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val weightF1', acc_val[\"weightF1\"] , epoch)\n",
    "        #writer.add_scalar('IoU/val MacroIoU', acc_val[\"IoU\"] , epoch)\n",
    "\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "\n",
    "    # Start EMA Evaluation\n",
    "    if (epoch % eval_every == 0 or epoch==1):\n",
    "        \n",
    "        logging.info(\"Saving models\")\n",
    "        model_dir = os.path.join(up(os.path.abspath(\"/home/ubuntu/Tesi/Early-Fusion\")), 'trained_models_EF')\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        torch.save(model_ema.ema.state_dict(), os.path.join(model_dir, 'model_ema.pth'))\n",
    "\n",
    "        val_loss_ema = []\n",
    "        val_batches_ema = 0\n",
    "        y_true_val_ema = []\n",
    "        y_predicted_val_ema = []\n",
    "                        \n",
    "        seed_all(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (image, target) in tqdm(val_loader, desc=\"validating\"):\n",
    "\n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                logits = model_ema.ema(image)\n",
    "                logits = F.upsample(input=logits, size=(target.shape[-2], target.shape[-1]), mode='bilinear')\n",
    "                loss = criterion(logits, target)\n",
    "\n",
    "                # Accuracy metrics only on annotated pixels\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,15))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                val_batches_ema += target.shape[0]\n",
    "                val_loss_ema.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted_val_ema += probs.argmax(1).tolist()\n",
    "                y_true_val_ema += target.tolist()\n",
    "                \n",
    "            y_predicted_val_ema = np.asarray(y_predicted_val_ema)\n",
    "            y_true_val_ema = np.asarray(y_true_val_ema)\n",
    "            #acc_val_ema = Evaluation(y_predicted_val_ema, y_true_val_ema)\n",
    "            #acc_val_ema = accuracy_score(y_true_val_ema, y_predicted_val_ema)\n",
    "        # Save Scores\n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"Evaluating EMA model..\")\n",
    "        logging.info(\"val loss was: \" + str(sum(val_loss_ema) / val_batches_ema))\n",
    "        logging.info(\"RESULTS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "        #logging.info(\"Evaluation: \" + str(acc_val_ema))\n",
    "        \n",
    "        #writer.add_scalars('Loss per epoch (EMA)', {'val loss':sum(val_loss_ema) / val_batches_ema}, epoch)\n",
    "        #writer.add_scalar('Precision/val macroPrec (EMA)', acc_val_ema[\"macroPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val microPrec (EMA)', acc_val_ema[\"microPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val weightPrec (EMA)', acc_val_ema[\"weightPrec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val macroRec (EMA)', acc_val_ema[\"macroRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val microRec (EMA)', acc_val_ema[\"microRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val weightRec (EMA)', acc_val_ema[\"weightRec\"] , epoch)\n",
    "        #writer.add_scalar('F1/val macroF1 (EMA)', acc_val_ema[\"macroF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val microF1 (EMA)', acc_val_ema[\"microF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val weightF1 (EMA)', acc_val_ema[\"weightF1\"] , epoch)\n",
    "        #writer.add_scalar('IoU/val MacroIoU (EMA)', acc_val_ema[\"IoU\"] , epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "standardization = transforms.Normalize(bands_mean, bands_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial True\n",
      "S 1\n",
      "D 512\n",
      "R 16\n",
      "train_steps 6\n",
      "eval_steps 7\n",
      "inv_t 100\n",
      "eta 0.9\n",
      "rand_init True\n",
      "init cfg None\n"
     ]
    }
   ],
   "source": [
    "models_list = []\n",
    "#models_files = glob(os.path.join(os.path.join(\"/home/ubuntu/Tesi/trained_models_EF\", '80'),'model_ema.pth'))\n",
    "models_files = glob(os.path.join(os.path.join(\"/home/ubuntu/Tesi/trained_models_EF\"),'model_ema.pth'))\n",
    "\n",
    "for model_file in models_files:\n",
    "\n",
    "    model = MariNext(11, 15)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    logging.info('Loading model files from folder: %s' % model_file)\n",
    "\n",
    "    checkpoint = torch.load(model_file, map_location = device)\n",
    "    checkpoint = {k.replace('decoder','decode_head'):v for k,v in checkpoint.items() if ('proj1' not in k) and ('proj2' not in k)}\n",
    "\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    del checkpoint  # dereference\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    models_list.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_band(path):\n",
    "    return int(path.split('_')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_predicted = []\n",
    "                            \n",
    "with torch.no_grad():\n",
    "    for (image, target) in tqdm(test_loader, desc=\"testing\"):\n",
    "\n",
    "        image = TTA(image)            \n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        seed_all(0)\n",
    "        \n",
    "        all_predictions = []\n",
    "        logits = model_ema.ema(image)\n",
    "        logits = F.upsample(input=logits, size=(target.shape[-2], target.shape[-1]), mode='bilinear')\n",
    "        \n",
    "        # Accuracy metrics only on annotated pixels\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        predictions = probs.argmax(1)\n",
    "        \n",
    "        predictions = TTA(predictions, reverse_aggregation = True)\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        all_predictions = torch.cat(all_predictions)\n",
    "        all_predictions = torch.mode(all_predictions, dim=0, keepdim=True)[0]\n",
    "            \n",
    "        \n",
    "        predictions = predictions.reshape(-1)\n",
    "        target = target.reshape(-1)\n",
    "        mask = target != -1\n",
    "        \n",
    "        predictions = predictions[mask].cpu().numpy()\n",
    "        target = target[mask]\n",
    "        \n",
    "        target = target.cpu().numpy()\n",
    "        \n",
    "        y_predicted += predictions.tolist()\n",
    "        y_true += target.tolist()\n",
    "\n",
    "    # Save Scores\n",
    "    #acc = Evaluation(y_predicted, y_true)\n",
    "    #logging.info(\"\\n\")\n",
    "    #logging.info(\"STATISTICS: \\n\")\n",
    "    #logging.info(\"Evaluation: \" + str(acc))\n",
    "    #print(\"Evaluation: \" + str(acc))\n",
    "    conf_mat = confusion_matrix(y_true, y_predicted, labels, True)\n",
    "    logging.info(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "    print(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "    \n",
    "                    \n",
    "    seed_all(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
