{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing packages and loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from time import time \n",
    "from tqdm import tqdm \n",
    "from glob import glob\n",
    "from os.path import dirname as up\n",
    "from rasterio.enums import Resampling\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from timm.utils import ModelEma\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from vscp import VSCP\n",
    "from test_time_aug import TTA\n",
    "from metrics import Evaluation, confusion_matrix\n",
    "from assets import bool_flag, cosine_scheduler, labels, mados_cat_mapping, mados_color_mapping\n",
    "#from dataset import MADOS, gen_weights, class_distr, bands_mean, bands_std\n",
    "from dataset_crop import MADOS, gen_weights, class_distr, bands_mean, bands_std\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = os.path.join(\"/home/ubuntu/Tesi/Early-Fusion-Unet\", 'log')\n",
    "time_now = str(int(time() / 60))\n",
    "log_file = os.path.join(log_directory, 'log_marinext_' + time_now + '.log')\n",
    "\n",
    "logging.basicConfig(filename=log_file, filemode='a', level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.info('*' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    # Pytorch Reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    # DataLoader Workers Reproducibility\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 09:31:05.165731: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 09:31:10.997066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "seed_all(0)\n",
    "g=torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "writer = SummaryWriter(os.path.join(log_directory, 'logs', 'tsboard_segm'+'_'+time_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_path = os.path.join(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\",'splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load train set to memory:   0%|          | 0/175 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "Load train set to memory: 100%|██████████| 175/175 [03:52<00:00,  1.33s/it]\n",
      "Load val set to memory: 100%|██████████| 175/175 [01:15<00:00,  2.31it/s]\n",
      "Load test set to memory: 100%|██████████| 175/175 [01:15<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_train = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'train')\n",
    "dataset_val = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'val')\n",
    "dataset_test = MADOS(\"/home/ubuntu/Tesi/MADOS_crop/MADOS\", splits_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train, \n",
    "                          batch_size = 5, \n",
    "                          shuffle = True,\n",
    "                          num_workers = 0,           # 0 is the main process\n",
    "                          pin_memory = False,        # Use pinned memory or not\n",
    "                          prefetch_factor = 2,       # Number of sample loaded in advance by each worker\n",
    "                          persistent_workers= False, # This allows to maintain the workers Dataset instances alive.\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g,\n",
    "                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(dataset_val, \n",
    "                          batch_size = 5, \n",
    "                          shuffle = False,\n",
    "                          num_workers = 0,           # 0 is the main process\n",
    "                          pin_memory = False,        # Use pinned memory or not\n",
    "                          prefetch_factor = 2,       # Number of sample loaded in advance by each worker\n",
    "                          persistent_workers= False, # This allows to maintain the workers Dataset instances alive.\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset_test, \n",
    "                          batch_size = 1, \n",
    "                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU presence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gpu or cpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(11, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.Unet('resnet18', in_channels=11, classes=15)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]          34,496\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "    ResNetEncoder-67  [[-1, 11, 224, 224], [-1, 64, 112, 112], [-1, 64, 56, 56], [-1, 128, 28, 28], [-1, 256, 14, 14], [-1, 512, 7, 7]]               0\n",
      "         Identity-68            [-1, 512, 7, 7]               0\n",
      "         Identity-69          [-1, 768, 14, 14]               0\n",
      "        Attention-70          [-1, 768, 14, 14]               0\n",
      "           Conv2d-71          [-1, 256, 14, 14]       1,769,472\n",
      "      BatchNorm2d-72          [-1, 256, 14, 14]             512\n",
      "             ReLU-73          [-1, 256, 14, 14]               0\n",
      "           Conv2d-74          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
      "             ReLU-76          [-1, 256, 14, 14]               0\n",
      "         Identity-77          [-1, 256, 14, 14]               0\n",
      "        Attention-78          [-1, 256, 14, 14]               0\n",
      "     DecoderBlock-79          [-1, 256, 14, 14]               0\n",
      "         Identity-80          [-1, 384, 28, 28]               0\n",
      "        Attention-81          [-1, 384, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         442,368\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-86          [-1, 128, 28, 28]             256\n",
      "             ReLU-87          [-1, 128, 28, 28]               0\n",
      "         Identity-88          [-1, 128, 28, 28]               0\n",
      "        Attention-89          [-1, 128, 28, 28]               0\n",
      "     DecoderBlock-90          [-1, 128, 28, 28]               0\n",
      "         Identity-91          [-1, 192, 56, 56]               0\n",
      "        Attention-92          [-1, 192, 56, 56]               0\n",
      "           Conv2d-93           [-1, 64, 56, 56]         110,592\n",
      "      BatchNorm2d-94           [-1, 64, 56, 56]             128\n",
      "             ReLU-95           [-1, 64, 56, 56]               0\n",
      "           Conv2d-96           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-97           [-1, 64, 56, 56]             128\n",
      "             ReLU-98           [-1, 64, 56, 56]               0\n",
      "         Identity-99           [-1, 64, 56, 56]               0\n",
      "       Attention-100           [-1, 64, 56, 56]               0\n",
      "    DecoderBlock-101           [-1, 64, 56, 56]               0\n",
      "        Identity-102        [-1, 128, 112, 112]               0\n",
      "       Attention-103        [-1, 128, 112, 112]               0\n",
      "          Conv2d-104         [-1, 32, 112, 112]          36,864\n",
      "     BatchNorm2d-105         [-1, 32, 112, 112]              64\n",
      "            ReLU-106         [-1, 32, 112, 112]               0\n",
      "          Conv2d-107         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-108         [-1, 32, 112, 112]              64\n",
      "            ReLU-109         [-1, 32, 112, 112]               0\n",
      "        Identity-110         [-1, 32, 112, 112]               0\n",
      "       Attention-111         [-1, 32, 112, 112]               0\n",
      "    DecoderBlock-112         [-1, 32, 112, 112]               0\n",
      "          Conv2d-113         [-1, 16, 224, 224]           4,608\n",
      "     BatchNorm2d-114         [-1, 16, 224, 224]              32\n",
      "            ReLU-115         [-1, 16, 224, 224]               0\n",
      "          Conv2d-116         [-1, 16, 224, 224]           2,304\n",
      "     BatchNorm2d-117         [-1, 16, 224, 224]              32\n",
      "            ReLU-118         [-1, 16, 224, 224]               0\n",
      "        Identity-119         [-1, 16, 224, 224]               0\n",
      "       Attention-120         [-1, 16, 224, 224]               0\n",
      "    DecoderBlock-121         [-1, 16, 224, 224]               0\n",
      "     UnetDecoder-122         [-1, 16, 224, 224]               0\n",
      "          Conv2d-123         [-1, 15, 224, 224]           2,175\n",
      "        Identity-124         [-1, 15, 224, 224]               0\n",
      "        Identity-125         [-1, 15, 224, 224]               0\n",
      "      Activation-126         [-1, 15, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 14,355,327\n",
      "Trainable params: 14,355,327\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.11\n",
      "Forward/backward pass size (MB): 239.45\n",
      "Params size (MB): 54.76\n",
      "Estimated Total Size (MB): 296.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (11, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMA è una forma di media mobile che attribuisce pesi decrescenti ai dati nel tempo, con un peso maggiore ai dati più recenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ema = None\n",
    "if True:\n",
    "    model_ema = ModelEma(\n",
    "        model,\n",
    "        decay=0.999,\n",
    "        device=device,\n",
    "        resume='')\n",
    "    \n",
    "    ema_decay_schedule = cosine_scheduler(0.999, 0.999, 80, len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Cross Entropy Loss & adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor(np.array([64.39, 28.33, 70.90, 75.34, 75.33, 19.25, 5.67, 26.99, 53.84, 23.63, 15.65, 75.48, 75.03, 76.19, 20.38])).float()\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction= 'none', weight=weight.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_on_plateau=0\n",
    "if reduce_lr_on_plateau==1:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "else:\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, '[45,65]', gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "eval_every = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/286 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "training: 100%|██████████| 286/286 [01:27<00:00,  3.27it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.12it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.52it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.14it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.23it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.08it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.41it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.42it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.87it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.32it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.49it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.32it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.60it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.36it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.75it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.18it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.62it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.31it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.31it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.45it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.25it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.66it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.64it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.43it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.68it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.42it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.85it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.44it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.39it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.32it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.42it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.60it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.94it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.26it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.47it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.22it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.60it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.25it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.64it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.69it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.69it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.35it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.43it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.23it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.44it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.45it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.88it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.30it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.75it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.78it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.73it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.23it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.65it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.21it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.35it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.31it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.77it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.43it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.59it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00,  9.95it/s]\n",
      "validating: 100%|██████████| 129/129 [00:13<00:00,  9.92it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.35it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.40it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.44it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.76it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.49it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.68it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.31it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.81it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.23it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.46it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.21it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.37it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.54it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.73it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.77it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.32it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.38it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.37it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.43it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.72it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.24it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.20it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.34it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.43it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.34it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.56it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.55it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.26it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.43it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.70it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.40it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.66it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.65it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.42it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.88it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.42it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.77it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.49it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.86it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.51it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.28it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.48it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.44it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.61it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.43it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.45it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.24it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.55it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.47it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.47it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.61it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.32it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.47it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.15it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.97it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.09it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.57it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.20it/s]\n",
      "validating: 100%|██████████| 129/129 [00:11<00:00, 10.94it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.20it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.46it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.67it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.36it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.49it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.47it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.59it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.69it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.42it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.57it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.21it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.53it/s]\n",
      "training: 100%|██████████| 286/286 [01:23<00:00,  3.41it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.38it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.63it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.52it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.36it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.25it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.31it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.35it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.58it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.55it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.50it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.39it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.40it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.73it/s]\n",
      "training: 100%|██████████| 286/286 [01:24<00:00,  3.37it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.36it/s]\n",
      "validating: 100%|██████████| 129/129 [00:12<00:00, 10.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "model.train()\n",
    "\n",
    "best_val_loss = 100\n",
    "best_val_loss_ema = 100\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    training_loss = []\n",
    "    training_batches = 0\n",
    "    \n",
    "    i_board = 0\n",
    "    for it, (image, target) in enumerate(tqdm(train_loader, desc=\"training\")):\n",
    "        \n",
    "        it = len(train_loader) * (epoch-1) + it  # global training iteration\n",
    "        \n",
    "        #VSCP\n",
    "        image_augmented, target_augmented = VSCP(image.cpu().numpy(), target.cpu().numpy())\n",
    "        image = torch.cat([image, torch.tensor(image_augmented).to(image.device)])\n",
    "        target = torch.cat([target, torch.tensor(target_augmented).to(target.device)])\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        torch.use_deterministic_algorithms(False)\n",
    "        logits = F.upsample(input=model(image), size=image.size()[2:4], mode='bilinear')\n",
    "        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "        logits = logits.reshape((-1,15))\n",
    "        target = target.reshape(-1)\n",
    "        mask = target != -1\n",
    "        logits = logits[mask]\n",
    "        target = target[mask]\n",
    "        loss = criterion(logits, target)\n",
    "        #loss = loss.mean()\n",
    "        loss = loss.sum() / weight[target].sum()\n",
    "        loss.backward() \n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        \n",
    "        training_batches += target.shape[0]\n",
    "\n",
    "        training_loss.append((loss.data*target.shape[0]).tolist())\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), float('inf'))\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        model_ema.decay = ema_decay_schedule[it]\n",
    "        model_ema.update(model)\n",
    "        \n",
    "        # Write running loss\n",
    "        writer.add_scalar('training loss', loss , (epoch - 1) * len(train_loader)+i_board)\n",
    "        i_board+=1\n",
    "    \n",
    "    logging.info(\"Training loss was: \" + str(sum(training_loss) / training_batches))\n",
    "    \n",
    "    logging.info(\"Saving models\")\n",
    "    model_dir = os.path.join(up(os.path.abspath(\"/home/ubuntu/Tesi/Early-Fusion-Unet\")), 'trained_models_EF_Unet')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    #torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "    \n",
    "    # Start Evaluation\n",
    "    if epoch % eval_every == 0 or epoch==1:\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = []\n",
    "        val_batches = 0\n",
    "        y_true_val = []\n",
    "        y_predicted_val = []\n",
    "        \n",
    "        seed_all(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (image, target) in tqdm(val_loader, desc=\"validating\"):\n",
    "                \n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                #torch.use_deterministic_algorithms(False)\n",
    "                logits = F.upsample(input=model(image), size=image.size()[2:4], mode='bilinear')\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,15))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                loss = criterion(logits, target)\n",
    "                #loss = loss.mean()\n",
    "                loss = loss.sum() / weight[target].sum()\n",
    "                #torch.use_deterministic_algorithms(True)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                val_batches += target.shape[0]\n",
    "                val_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted_val += probs.argmax(1).tolist()\n",
    "                y_true_val += target.tolist()\n",
    "                    \n",
    "                \n",
    "            y_predicted_val = np.asarray(y_predicted_val)\n",
    "            y_true_val = np.asarray(y_true_val)\n",
    "            #acc_val = Evaluation(y_predicted_val, y_true_val)\n",
    "            \n",
    "        val_loss_mean = sum(val_loss) / val_batches\n",
    "\n",
    "        # Check if the current validation loss is the best encountered so far\n",
    "        if val_loss_mean < best_val_loss:\n",
    "            best_val_loss = val_loss_mean\n",
    "            logging.info(\"Found new best validation loss at epoch {}: {}\".format(epoch, best_val_loss))\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "            \n",
    "        # Save Scores    \n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"Evaluating model..\")\n",
    "        logging.info(\"Val loss was: \" + str(sum(val_loss) / val_batches))\n",
    "        logging.info(\"RESULTS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "        #logging.info(\"Evaluation: \" + str(acc_val))\n",
    "        \n",
    "        writer.add_scalars('Loss per epoch', {'Val loss':sum(val_loss) / val_batches, \n",
    "                                                'Train loss':sum(training_loss) / training_batches}, epoch)\n",
    "        \n",
    "        #writer.add_scalar('Precision/val macroPrec', acc_val[\"macroPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val microPrec', acc_val[\"microPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val weightPrec', acc_val[\"weightPrec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val macroRec', acc_val[\"macroRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val microRec', acc_val[\"microRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val weightRec', acc_val[\"weightRec\"] , epoch)\n",
    "        #writer.add_scalar('F1/val macroF1', acc_val[\"macroF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val microF1', acc_val[\"microF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val weightF1', acc_val[\"weightF1\"] , epoch)\n",
    "        #writer.add_scalar('IoU/val MacroIoU', acc_val[\"IoU\"] , epoch)        \n",
    "\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "\n",
    "    # Start EMA Evaluation\n",
    "    if (epoch % eval_every == 0 or epoch==1):\n",
    "        \n",
    "        logging.info(\"Saving models\")\n",
    "        model_dir = os.path.join(up(os.path.abspath(\"/home/ubuntu/Tesi/Early-Fusion-Unet\")), 'trained_models_EF_Unet')\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        #torch.save(model_ema.ema.state_dict(), os.path.join(model_dir, 'model_ema.pth'))\n",
    "\n",
    "        val_loss_ema = []\n",
    "        val_batches_ema = 0\n",
    "        y_true_val_ema = []\n",
    "        y_predicted_val_ema = []\n",
    "                        \n",
    "        seed_all(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (image, target) in tqdm(val_loader, desc=\"validating\"):\n",
    "                \n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                logits = model_ema.ema(image)\n",
    "                #torch.use_deterministic_algorithms(False)\n",
    "                logits = F.upsample(input=logits, size=image.size()[2:4], mode='bilinear')\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,15))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                loss = criterion(logits, target) # Calcolo della loss\n",
    "                #loss = loss.mean()\n",
    "                loss = loss.sum() / weight[target].sum()\n",
    "                #torch.use_deterministic_algorithms(True)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                val_batches_ema += target.shape[0]\n",
    "                val_loss_ema.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted_val_ema += probs.argmax(1).tolist()\n",
    "                y_true_val_ema += target.tolist()\n",
    "                \n",
    "            y_predicted_val_ema = np.asarray(y_predicted_val_ema)\n",
    "            y_true_val_ema = np.asarray(y_true_val_ema)\n",
    "            #acc_val_ema = Evaluation(y_predicted_val_ema, y_true_val_ema)\n",
    "            \n",
    "        val_loss_mean = sum(val_loss_ema) / val_batches_ema\n",
    "\n",
    "        # Check if the current validation loss is the best encountered so far\n",
    "        if val_loss_mean < best_val_loss_ema:\n",
    "            best_val_loss_ema = val_loss_mean\n",
    "            logging.info(\"Found new best validation loss at epoch {}: {}\".format(epoch, best_val_loss_ema))\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), os.path.join(model_dir, 'model_ema.pth'))\n",
    "            \n",
    "        # Save Scores\n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"Evaluating EMA model..\")\n",
    "        logging.info(\"val loss was: \" + str(sum(val_loss_ema) / val_batches_ema))\n",
    "        logging.info(\"RESULTS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "        #logging.info(\"Evaluation: \" + str(acc_val_ema))\n",
    "        \n",
    "        writer.add_scalars('Loss per epoch (EMA)', {'val loss':sum(val_loss_ema) / val_batches_ema}, epoch)\n",
    "        #writer.add_scalar('Precision/val macroPrec (EMA)', acc_val_ema[\"macroPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val microPrec (EMA)', acc_val_ema[\"microPrec\"] , epoch)\n",
    "        #writer.add_scalar('Precision/val weightPrec (EMA)', acc_val_ema[\"weightPrec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val macroRec (EMA)', acc_val_ema[\"macroRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val microRec (EMA)', acc_val_ema[\"microRec\"] , epoch)\n",
    "        #writer.add_scalar('Recall/val weightRec (EMA)', acc_val_ema[\"weightRec\"] , epoch)\n",
    "        #writer.add_scalar('F1/val macroF1 (EMA)', acc_val_ema[\"macroF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val microF1 (EMA)', acc_val_ema[\"microF1\"] , epoch)\n",
    "        #writer.add_scalar('F1/val weightF1 (EMA)', acc_val_ema[\"weightF1\"] , epoch)\n",
    "        #writer.add_scalar('IoU/val MacroIoU (EMA)', acc_val_ema[\"IoU\"] , epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ema.ema.state_dict(), os.path.join(model_dir, 'model_ema_80.pth'))\n",
    "torch.save(model.state_dict(), os.path.join(model_dir, 'model_80.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list2 = []\n",
    "#models_files = glob(os.path.join(os.path.join(\"C:\\\\Users\\\\lucap\\\\OneDrive\\\\Desktop\\\\Tesi\\\\Python Code\\\\trained_models_finito\", '1'),'*.pth'))\n",
    "models_files = glob(os.path.join(os.path.join(\"/home/ubuntu/Tesi/trained_models_EF_Unet\"),'model_ema_80.pth'))\n",
    "#models_files = glob(\"C:\\Users\\lucap\\OneDrive\\Desktop\\Tesi\\trained_models\\10\\model_ema.pth\")\n",
    "\n",
    "for model_file in models_files:\n",
    "\n",
    "    #model2 = MariNext(11, 15)\n",
    "    model2 = smp.Unet('resnet18', in_channels=11, classes=15)\n",
    "    torch.nn.init.xavier_uniform_(model2.encoder.conv1.weight)\n",
    "\n",
    "    model2.to(device)\n",
    "\n",
    "    # Load model from specific epoch to continue the training or start the evaluation\n",
    "    \n",
    "    logging.info('Loading model files from folder: %s' % model_file)\n",
    "\n",
    "    checkpoint = torch.load(model_file, map_location = device)\n",
    "    checkpoint = {k.replace('decode_head','decoder'):v for k,v in checkpoint.items() if ('proj1' not in k) and ('proj2' not in k)}\n",
    "\n",
    "    model2.load_state_dict(checkpoint)\n",
    "\n",
    "    del checkpoint  # dereference\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model2.eval()\n",
    "    \n",
    "    models_list2.append(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_predicted = []\n",
    "                            \n",
    "with torch.no_grad():\n",
    "    for (image, target) in tqdm(test_loader, desc=\"testing\"):\n",
    "\n",
    "        image = TTA(image)            \n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        logits = model2(image)\n",
    "        logits = F.upsample(input=logits, size=(target.shape[-2], target.shape[-1]), mode='bilinear')\n",
    "            \n",
    "        # Accuracy metrics only on annotated pixels\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        predictions = probs.argmax(1)\n",
    "        \n",
    "        predictions = TTA(predictions, reverse_aggregation = True)\n",
    "            \n",
    "        predictions = predictions.reshape(-1)\n",
    "        target = target[0].reshape(-1)\n",
    "        mask = target != -1\n",
    "        \n",
    "        predictions = predictions[mask].cpu().numpy()\n",
    "        target = target[mask]\n",
    "        \n",
    "        target = target.cpu().numpy()\n",
    "\n",
    "        y_predicted += predictions.tolist()\n",
    "        y_true += target.tolist()\n",
    "\n",
    "    # Save Scores\n",
    "    #acc = Evaluation(y_predicted, y_true)\n",
    "    #logging.info(\"\\n\")\n",
    "    #logging.info(\"STATISTICS: \\n\")\n",
    "    #logging.info(\"Evaluation: \" + str(acc))\n",
    "    #print(\"Evaluation: \" + str(acc))\n",
    "    conf_mat = confusion_matrix(y_true, y_predicted, labels, True)\n",
    "    logging.info(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "    print(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
